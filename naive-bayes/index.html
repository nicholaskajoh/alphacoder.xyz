<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Naive Bayes | Alpha Coder</title>

    <style>body{margin:40px auto;max-width:650px;line-height:1.6;font-size:18px;color:#444;padding:0 10px}h1,h2,h3{line-height:1.2}div.header h1{padding-top:0;padding-bottom:8px;margin-bottom:24px;font-size:18px;font-weight:400;border-bottom:1px solid}.header-menu{float:right}.header-menu a{padding-left:5px}ul.pagination{list-style-type:none;text-align:center;padding:0}ul.pagination>li{padding:0 8px;display:inline-block}div.footer{border-top:1px solid;text-align:center}.footer-links a{padding:0 5px}img{max-width:100%;max-height:100%;display:block;margin-left:auto;margin-right:auto}a,a:visited,a:hover,a:active{color:#00e}.posts-list li:not(:last-child){padding-bottom:20px}.post-meta a:not(:last-child){padding-right:5px}blockquote{margin-top:10px;margin-bottom:10px;margin-left:50px;padding-left:15px;border-left:3px solid #ccc;background-color:#f9f9f9;font-style:italic}</style>
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-82728104-5', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    

    

    <meta property="og:title" content="Naive Bayes" />
<meta property="og:description" content="Naive Bayes is a classifier just like K Nearest Neighbors. The Naive Bayes algorithm applies the popular Bayes Theorem (used to calculate conditional probability) given by the formula:
Bayes formula
Here’s a great explanation to read if you’ve not come across/don’t understand the theorem yet: https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem.
The ML Chops series  Linear Regression K Nearest Neighbors Naive Bayes (this article) Support Vector Machine K Means  Let’s consider the data we used in the last post on KNNs:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://alphacoder.xyz/naive-bayes/" />
<meta property="article:published_time" content="2017-12-26T08:44:05&#43;01:00"/>
<meta property="article:modified_time" content="2017-12-26T08:44:05&#43;01:00"/>

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Naive Bayes"/>
<meta name="twitter:description" content="Naive Bayes is a classifier just like K Nearest Neighbors. The Naive Bayes algorithm applies the popular Bayes Theorem (used to calculate conditional probability) given by the formula:
Bayes formula
Here’s a great explanation to read if you’ve not come across/don’t understand the theorem yet: https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem.
The ML Chops series  Linear Regression K Nearest Neighbors Naive Bayes (this article) Support Vector Machine K Means  Let’s consider the data we used in the last post on KNNs:"/>

    
<meta itemprop="name" content="Naive Bayes">
<meta itemprop="description" content="Naive Bayes is a classifier just like K Nearest Neighbors. The Naive Bayes algorithm applies the popular Bayes Theorem (used to calculate conditional probability) given by the formula:
Bayes formula
Here’s a great explanation to read if you’ve not come across/don’t understand the theorem yet: https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem.
The ML Chops series  Linear Regression K Nearest Neighbors Naive Bayes (this article) Support Vector Machine K Means  Let’s consider the data we used in the last post on KNNs:">


<meta itemprop="datePublished" content="2017-12-26T08:44:05&#43;01:00" />
<meta itemprop="dateModified" content="2017-12-26T08:44:05&#43;01:00" />
<meta itemprop="wordCount" content="1012">



<meta itemprop="keywords" content="ML Chops Series," />

</head>


<body>
<div class="header">
    <h1>
        <a href="/">Alpha Coder</a>
        <div class="header-menu">
            <a href="/blog/">Blog</a>
            <a href="/courses/">Courses</a>
            <a href="https://tinyletter.com/nicholaskajoh">Newsletter</a>
        </div>
    </h1>
</div>
<div id="content">

<header>
    <h1>Naive Bayes</h1>
    

<div class="post-meta">
    <time datetime="2017-12-26">Dec 26, 2017</time>
    | Tags:
    <a href="http://alphacoder.xyz/tag/ml-chops-series/">ML Chops Series</a>
</div>
</header>
<article>
    

<p><img src="/images/mlc-nb/nb-meme.jpeg" alt="" /></p>

<p>Naive Bayes is a classifier just like <a href="/k-nearest-neighbors">K Nearest Neighbors</a>. The Naive Bayes algorithm applies the popular <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes Theorem</a> (used to calculate conditional probability) given by the formula:</p>

<p><img src="/images/mlc-nb/bayes-formula.png" alt="" />
<em>Bayes formula</em></p>

<p>Here’s a great explanation to read if you’ve not come across/don’t understand the theorem yet: <a href="https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem">https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem</a>.</p>

<h1 id="the-ml-chops-series">The ML Chops series</h1>

<ul>
<li><a href="/linear-regression">Linear Regression</a></li>
<li><a href="/k-nearest-neighbors">K Nearest Neighbors</a></li>
<li>Naive Bayes (this article)</li>
<li><a href="/support-vector-machine">Support Vector Machine</a></li>
<li><a href="/k-means">K Means</a></li>
</ul>

<p>Let’s consider the data we used in the last post on KNNs:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">height (ft)    weight (kg)    sex  
6.3            50.2           Male  
5.9            79.7           Female  
5.1            61.4           Female  
5.6            47.1           Male  
5.1            59.8           Female</pre></td></tr></table>
</div>
</div>
<p>In Naive Bayes, we calculate the probabilities of an input feature set being in each of the classes in the data and return the class with the highest probability as the predicted output.</p>

<p>Our goal with the data in the table above is to determine whether an individual is <em>Male</em> or <em>Female</em>. Given the height and weight of a person e.g <code>[height, weight] -&gt; [5.8, 82.1]</code>, a Naive Bayes classifier calculates the probabilities of the person being a Male and a Female e.g <code>[(“Male”, 7.92248128417e-103), (“Female”, 0.00355626444241)]</code> then returns the class with the highest probability (in this example <code>“Female”</code>).</p>

<p>How do we find the probabilities for each class?</p>

<p>You guessed right! <strong>Bayes formula</strong>.</p>

<p>Let’s put the formula into context for better understanding:</p>

<p><img src="/images/mlc-nb/male-person-prob.png" alt="" />
<em>Probability that a person is Male</em></p>

<p>Substitute <em>Female</em> for <em>Male</em> in the formula and you have the probability that a person is female.</p>

<p>Let’s explain terms in the equation briefly:</p>

<ul>
<li><strong>P(Male | height &amp; weight)</strong> is the probability that a person is Male given their height and weight (better put: given all the features provided in the data). This is what we’re looking for.</li>
<li><strong>P(Male)</strong> is the probability of selecting a Male person from the data.</li>
<li><strong>P(height | Male)</strong> and <strong>P(weight | Male)</strong> equate to <strong>P(B|A)</strong> [from the first formula]. <strong>P(height | Male)</strong> is the probability of getting the height of a person given that they are Male (same for the weight). Essentially we want to find the percentage of Males with the same height as the person we’re classifying. This not feasible with our data however because both height and weight are continuous. Besides, it would be very costly when we have a large amount of training data (we’d have to run through the data every time to count the number of people with same height and weight with the person being classified). Thankfully, we have the <strong>Probability Density Function (PDF)</strong> to help us with this. We’ll use PDF to determine both <strong>P(height | Male)</strong> and <strong>P(weight | Male)</strong> in a bit.</li>
<li><strong>P(height &amp; weight)</strong> or better put <strong>P(all features)</strong> is the <a href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal probability</a>. For our classification, it’s not really useful to us because it’s the denominator for all class probabilities. We’re actually interested in finding the class with the highest probability and not the actually probability figure like 0.9 for instance. We might as well not use it since we’re dividing by it in every class probability calculation. It doesn’t change anything. We’ll still get the class with the highest probability.</li>
</ul>

<h1 id="p-class">P(Class)</h1>

<p>The probability of selecting a person from a given class is the simplest calculation to perform. From the data table, we can see that there are 5 samples. 2 are Male. Thus <strong>P(Male)</strong> = <sup>2</sup>&frasl;<sub>5</sub>. And 3 are Female. Thus <strong>P(Female)</strong> = <sup>3</sup>&frasl;<sub>5</sub>.</p>

<h1 id="the-pdf">The PDF</h1>

<p>The <a href="https://en.wikipedia.org/wiki/Probability_density_function">PDF</a> can be computed using the following formula:</p>

<p><img src="/images/mlc-nb/pdf.png" alt="" />
<em>The PDF</em></p>

<p>Substitute Female with Male and/or weight with height to calculate other PDFs.</p>

<p>Using PDF, we assume:</p>

<ul>
<li>Each feature is uncorrelated from the others (i.e height is independent of weight for instance).</li>
<li>The values of the features (i.e heights, weights) are <a href="https://www.thoughtco.com/what-is-normal-distribution-3026707">normally distributed</a>.</li>
</ul>

<p>These are assumptions and are not completely true most times for a given data set. As such, we’re being “naive” by assuming.</p>

<h1 id="code">Code</h1>

<p>First things first! The data.</p>

<p>For convenience, I’m using 3 arrays:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">import</span> <span style="color:#008b45;text-decoration:underline">numpy</span> <span style="color:#8b008b;font-weight:bold">as</span> <span style="color:#008b45;text-decoration:underline">np</span>

<span style="color:#228b22"># data  </span>
heights = np.array([<span style="color:#b452cd">6.3</span>, <span style="color:#b452cd">5.9</span>, <span style="color:#b452cd">5.1</span>, <span style="color:#b452cd">5.6</span>, <span style="color:#b452cd">5.1</span>])  
weights = np.array([<span style="color:#b452cd">50.2</span>, <span style="color:#b452cd">79.7</span>, <span style="color:#b452cd">61.4</span>, <span style="color:#b452cd">47.1</span>, <span style="color:#b452cd">59.8</span>])  
classes = np.array([<span style="color:#cd5555">&#34;Male&#34;</span>, <span style="color:#cd5555">&#34;Female&#34;</span>, <span style="color:#cd5555">&#34;Female&#34;</span> , <span style="color:#cd5555">&#34;Male&#34;</span>, <span style="color:#cd5555">&#34;Female&#34;</span>])</code></pre></td></tr></table>
</div>
</div>
<p>Next, let’s find P(Class) for Male and Female:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">males_count = <span style="color:#b452cd">0</span>  
females_count = <span style="color:#b452cd">0</span>  
sample_size = <span style="color:#658b00">len</span>(classes)  
<span style="color:#8b008b;font-weight:bold">for</span> x <span style="color:#8b008b">in</span> classes:  
    <span style="color:#8b008b;font-weight:bold">if</span> x == <span style="color:#cd5555">&#34;Male&#34;</span>:  
        males_count += <span style="color:#b452cd">1</span>  
    <span style="color:#8b008b;font-weight:bold">else</span>:  
        females_count += <span style="color:#b452cd">1</span>  
p_male = males_count / sample_size  
p_female = females_count / sample_size</code></pre></td></tr></table>
</div>
</div>
<h1 id="pdfs">PDFs</h1>

<p>We need to find the various means and variances required to compute the PDFs:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">heights_of_males = []  
weights_of_males = []  
heights_of_females = []  
weights_of_females = []

<span style="color:#8b008b;font-weight:bold">for</span> i <span style="color:#8b008b">in</span> <span style="color:#658b00">range</span>(sample_size):  
    <span style="color:#8b008b;font-weight:bold">if</span> classes[i] == <span style="color:#cd5555">&#34;Male&#34;</span>:  
        heights_of_males.append(heights[i])  
        weights_of_males.append(weights[i])  
    <span style="color:#8b008b;font-weight:bold">else</span>:
        heights_of_females.append(heights[i])  
        weights_of_females.append(weights[i])

mean_height_males = np.mean(heights_of_males)  
mean_weight_males = np.mean(weights_of_males)  
mean_height_females = np.mean(heights_of_females)  
mean_weight_females = np.mean(weights_of_females)  
var_height_males = np.var(heights_of_males)  
var_weight_males = np.var(weights_of_males)  
var_height_females = np.var(heights_of_females)  
var_weight_females = np.var(weights_of_females)</code></pre></td></tr></table>
</div>
</div>
<p>Now to the PDF formula in code&hellip;</p>

<p>Let’s define a function as we’ll use it severally:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#8b008b;font-weight:bold">def</span> <span style="color:#008b45">the_pdf</span>(x, mean, variance):  
    pd = <span style="color:#b452cd">1</span> / (np.sqrt(<span style="color:#b452cd">2</span> * np.pi * variance)) * np.exp((-(x - mean)**<span style="color:#b452cd">2</span>) / (<span style="color:#b452cd">2</span> * variance))  
    <span style="color:#8b008b;font-weight:bold">return</span> pd</code></pre></td></tr></table>
</div>
</div>
<h1 id="predict">Predict</h1>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x = [<span style="color:#b452cd">5.8</span>, <span style="color:#b452cd">82.1</span>] <span style="color:#228b22"># [height, weight]</span>

p_height_male = the_pdf(x[<span style="color:#b452cd">0</span>], mean_height_males, var_height_males)
p_weight_male = the_pdf(x[<span style="color:#b452cd">1</span>], mean_weight_males, var_weight_males)
p_height_female = the_pdf(x[<span style="color:#b452cd">0</span>], mean_height_females, var_height_females)
p_weight_female = the_pdf(x[<span style="color:#b452cd">1</span>], mean_weight_females, var_weight_females)


<span style="color:#228b22"># Get class probabilities  </span>
p_male_h_and_w = p_male * p_height_male * p_weight_male  
p_female_h_and_w = p_female * p_height_female * p_weight_female  
<span style="color:#8b008b;font-weight:bold">print</span>(<span style="color:#cd5555">&#34;P(Male | height &amp; weight) =&#34;</span>, p_male_h_and_w)  
<span style="color:#8b008b;font-weight:bold">print</span>(<span style="color:#cd5555">&#34;P(Female | height &amp; weight) =&#34;</span>, p_female_h_and_w)

<span style="color:#228b22"># Return prediction  </span>
<span style="color:#8b008b;font-weight:bold">if</span> p_male_h_and_w &gt; p_female_h_and_w:  
    <span style="color:#8b008b;font-weight:bold">print</span>(<span style="color:#cd5555">&#34;class = Male&#34;</span>)  
<span style="color:#8b008b;font-weight:bold">else</span>:  
    <span style="color:#8b008b;font-weight:bold">print</span>(<span style="color:#cd5555">&#34;class = Female&#34;</span>)</code></pre></td></tr></table>
</div>
</div>
<p>Output:</p>
<div class="highlight"><div style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4">P(Male | height &amp; weight) = 7.92248128417e-103  
P(Female | height &amp; weight) = 0.00355626444241  
class = Female</pre></td></tr></table>
</div>
</div>
<p>Putting everything together, we have:</p>

<script src="https://gist.github.com/nicholaskajoh/3ae130a7e7df91141c3efdbc7a989304.js"></script>

<p>Don’t forget to check out the ML Chops repo for a more robust and efficient implementation: <a href="https://github.com/nicholaskajoh/ML_Chops/tree/master/naive-bayes">https://github.com/nicholaskajoh/ML_Chops/tree/master/naive-bayes</a>.</p>

<p>If you have any questions, concerns or suggestions, don’t hesitate to comment! 👍</p>

</article>


<form
  style="border: 1px solid #ccc; padding: 3px; text-align: center; border-radius: 2px; margin: 15px 0;"
  action="https://tinyletter.com/nicholaskajoh"
  method="post"
  target="popupwindow" onsubmit="window.open('https://tinyletter.com/nicholaskajoh', 'popupwindow', 'scrollbars=yes,width=800,height=600');return true">
    <div style="padding: 5px;">
      <h2>Subscribe to the Alpha Coder Newsletter!</h2>

      <p>Get timely updates on new articles, courses and more from Nicholas Kajoh. Unsubscribe anytime.</p>
      
      <input
        type="text"
        style="width: 150px; height: 30px; padding-left: 5px; border: 1px solid #ccc; border-radius: 2px;"
        name="email"
        placeholder="night.king@westeros.org">
      <input type="hidden" value="1" name="embed">
      <input
        type="submit"
        style="height: 34px; color: #fff; background-color: #00e; border: 1px solid #00e; border-radius: 2px;"
        value="Subscribe">
      
      <p>
        Enjoy the content on Alpha Coder? Please <a href="http://buymeacoff.ee/nicholaskajoh" target="_blank">buy me a coffee</a>. 😊
      </p>
    </div>
</form>



  <br><div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "alphacoderxyz" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



    </div>
<div class="footer">
    
    
    <div class="footer-links">
        <a href="http://twitter.com/nicholaskajoh">Twitter</a>
        <a href="https://github.com/nicholaskajoh">GitHub</a>
        <a href="http://buymeacoff.ee/nicholaskajoh">Buy me a coffee</a>
        <a href="/post/index.xml">RSS</a>
    </div>
    

    
    
    <div class="copyright">© Nicholas Kajoh</div>
    
</div>


<script src="https://unpkg.com/medium-zoom@1.0.4/dist/medium-zoom.min.js"></script>
<script>
  mediumZoom(document.querySelectorAll('img'));
</script></body>

</html>